# LambdaGrid Queues

Here is some information about how to get the app running locally. In addition,
there is some information about the current design. Keep in mind that the prototype
was thrown together very fast, and some parts of it are jank. However, the overall architecture is solid.

## Setup Instructions

There are two dependencies of the current prototype: Amazon SQS and Postgres.

### AWS

Get the AWS CLI as documented [here](https://docs.aws.amazon.com/cli/latest/userguide/installing.html). Then, run `aws configure` on the command line. It will ask you for your access key ID and secret. You can find these in the [IAM console](https://console.aws.amazon.com/iam/home?region=us-west-2#/users) under the user's Security Credentials tab. You may want to create a user with SQS permissions. Right now, that's the only permissions it needs.

Once you have configured the `aws cli`, the AWS portion of the setup is done.

### Postgres

Get a Postgres database running locally. If you are on Mac OSX, one easy
way to do this is with [Postgres.app](https://postgresapp.com/).

Once you have the app, you need to create the `lambdagrid` user (usually just with `createuser lambdagrid`) and the
`lambdagrid`database (with `psql -U lambdagrid` and `CREATE DATABASE lambdagrid;`).

Then, you need to execute some SQL statements. Hop into `psql` with the lambdagrid user and lambdagrid DB with `psql -U lambdagrid lambdagrid` and execute the statements below. One easy thing to do would be to
automate the schema creation.

```sql
CREATE TABLE accounts (
    id SERIAL PRIMARY KEY,
    account_name text NOT NULL UNIQUE,
    auth_key text NOT NULL UNIQUE,
    auth_secret text NOT NULL
);

CREATE UNIQUE INDEX accounts_pkey ON accounts(id int4_ops);
CREATE UNIQUE INDEX accounts_account_name_key ON accounts(account_name text_ops);
CREATE UNIQUE INDEX accounts_auth_key_key ON accounts(auth_key text_ops);

CREATE TABLE queues (
    name text PRIMARY KEY,
    owner_id integer NOT NULL REFERENCES accounts(id) ON DELETE CASCADE ON UPDATE CASCADE,
    queue_url text
);

CREATE UNIQUE INDEX queues_pkey ON queues(name text_ops);
```

### Golang

You need the Go tools installed to build the app. [Follow the instructions on this page](https://golang.org/doc/install#install). It basically consists of downloading the installer for your OS and then creating the directory `$HOME/go`.

I **highly** suggest downloading the Atom editor with the `go-plus` extension, which
will compile and run unit tests on save, automatically overlay coverage data, and also supports jumping to definitions.

### Cloning the repository

Clone the repository into `$HOME/go/src/github.com/lambdagrid/queues`.

### Downloading the dependencies

Run `cd $HOME/go/src/github.com/lambdagrid/queues; go get ./...`.

### Running the app

Run `go run main.go`. The web server will start listening on port 8080. To build
the binary, just run `go build`.

### Exercising the API

I like to use [Postman](https://www.getpostman.com/) to query the API. You can find the collection of requests I used to test it in the file `lambdagrid.postman_collection.json` in this repository. Use the "Register new account" request to get an API key and secret. Then edit the request group variables to set these as the `authKey` and `authSecret`. The rest of the request should just work then.

## Architecture

The imagined architecture consists of four primary components:
* The stateless server layer (in this repository)
* Some stateful metadata store (in this case, Postgres)
* The backend queue provider (SQS)
* The backend tailers (billing, archival, etc., not yet written)

The point of this product is to provide an extremely simple and feature rich queueing solution for startups. It is not meant to compete with Amazon on price - usually never a good idea for any business. Instead, the ease of use and add-on features of this product are what make it valuable.

This prototype currently consists of the first three components. The fourth will be written by copying messages into multiple queues and having workers consuming from those queues, performing operations like archiving, billing, and statistics.

## Implementation Details

### How authentication works
The first file to take a look at is `auth/interface.go`. It defines an interface
which defines two methods: `Check()`, to validate whether an auth/secret pair is
valid, and `CreateAccount()` to create an account. There are currently two implementations of this. The first, `mock`, is a mock authentication provider which
allows unit tests to pass. The second is `jankpersisted`, which uses Postgres to store authentication data. Let's focus on that.

Authentication keys/secrets are generated by generating 64 bytes of cryptographically random data and slicing it in half. This results in a 256 bit secret key, which is in-line with the NSA's recommendations for quantum resistant AES keys. Those keys are then encoded with base64 and stored in the database. **In order to be secure, hashing/per-key-salting needs to be added**.

Auth checks are performed by doing a DB lookup and comparing the provided auth secret to the auth secret stored in the database. Again, hashing/salting needs to be added to have security. In addition, this is perfect use case for caching in order to improve performance and reduce infrastructure costs.

### How the authentication middleware works

Authentication is added to endpoints using `middleware/auth.go`. All this file
does is validates the authentication headers, runs the authentication check with the authentication provider, and fails/passes the request.

### How the server works

The file `main.go` initializes the Postgres database object. It then uses that
object to initialize the authenticator and the server. It then
starts the server.

The first file to take a look at that is server specific is `server.go`. It creates an AWS session, constructs the server struct, and defines the routes. The routes are defined using a method, a path, and the method used to handle that path. You can see the authentication middleware there.

Let's take a look at a sample endpoint, the queue creation endpoint.

```go
func (s Server) createQueue() httprouter.Handle {
	type createQueueRequest struct {
		QueueName *string `json:"name"`
	}

	return func(w http.ResponseWriter, r *http.Request, _ httprouter.Params) {
```

You'll see that each endpoint actually returns a closure. This allows expensive
initialization to be done per-endpoint. Most endpoints are some cycle of decoding
request JSON, performing calls to Postgres or AWS, and constructing a response. I won't explain that in detail here. Lots of code needs to be deduplicated, but
this is a fairly standard structure.

### How tests will work
Go can compile a binary/run unit tests so fast that it is feasible to run them
on every file save during development. I have my editor configured to do this and would suggest you do it too.

The reason why this prototype doesn't have unit tests is I needed to integrate the database and SQS very fast and didn't have time to write mocks. The way to do this would be to have a similar setup to the auth provider - have an interface, implement an in-memory mock, and use that in unit tests. You can see two inactive unit tests at `server/status_test.go` and `server/jobwrite_test.go`. This actually will create a new server, run the server, construct a JSON payload, send the JSON payload to the server, and evaluate the response. This is as close to an integration test as you can get.


## Some easy things to do next

* Automate schema creation
* Add auth secret hashing/salting
* Re-enable tests by creating a DB handler interface/in-memory
* Add request logging and monitoring middleware
* Deduplicate lots of shared code in requests
* Set up hot reloading
* Move the `main.go` file into some subdirectory like `cmd/server/main.go`
* Potentially replace the router if it needs to be more feature rich
* Make certain endpoints (queue creation) safer to interrupt and leave data in a good state (roll back certain operations)
* Containerize for ease of setup, testing, and deployment
* Create a production deployment
* Support tailers, starting with archival
